{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone --depth 1 https://github.com/EleutherAI/lm-evaluation-harness\n#cd lm-evaluation-harness\n#pip install -e .","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!lm_eval --model hf --model_args pretrained=HuggingFaceTB/SmolLM-135M-Instruct,dtype=\"float16\" \\\n--tasks winogrande,lambada_openai --device \"cuda:0\" --batch_size 256 --output_path \"./out\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T11:53:16.637544Z","iopub.execute_input":"2025-04-26T11:53:16.637855Z","iopub.status.idle":"2025-04-26T11:55:00.061152Z","shell.execute_reply.started":"2025-04-26T11:53:16.637829Z","shell.execute_reply":"2025-04-26T11:55:00.060275Z"}},"outputs":[{"name":"stdout","text":"2025-04-26 11:53:31.485544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745668411.754848     121 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745668411.830392     121 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nconfig.json: 100%|█████████████████████████████| 723/723 [00:00<00:00, 4.69MB/s]\ntokenizer_config.json: 100%|███████████████| 3.59k/3.59k [00:00<00:00, 20.1MB/s]\nvocab.json: 100%|████████████████████████████| 801k/801k [00:00<00:00, 14.1MB/s]\nmerges.txt: 100%|████████████████████████████| 466k/466k [00:00<00:00, 36.4MB/s]\ntokenizer.json: 100%|██████████████████████| 2.10M/2.10M [00:00<00:00, 35.6MB/s]\nspecial_tokens_map.json: 100%|█████████████████| 565/565 [00:00<00:00, 4.02MB/s]\nXet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\nmodel.safetensors: 100%|█████████████████████▉| 269M/269M [00:01<00:00, 230MB/s]\ngeneration_config.json: 100%|██████████████████| 156/156 [00:00<00:00, 1.34MB/s]\nREADME.md: 100%|███████████████████████████| 4.99k/4.99k [00:00<00:00, 23.5MB/s]\nlambada_openai.py: 100%|███████████████████| 4.82k/4.82k [00:00<00:00, 29.6MB/s]\nXet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n0000.parquet: 100%|████████████████████████| 1.16M/1.16M [00:00<00:00, 20.7MB/s]\nGenerating test split: 100%|██████| 5153/5153 [00:00<00:00, 88561.47 examples/s]\nREADME.md: 100%|███████████████████████████| 9.97k/9.97k [00:00<00:00, 47.1MB/s]\nwinogrande.py: 100%|███████████████████████| 5.65k/5.65k [00:00<00:00, 31.2MB/s]\nDownloading data: 100%|█████████████████████| 3.40M/3.40M [00:00<00:00, 226MB/s]\nGenerating train split: 100%|███| 40398/40398 [00:01<00:00, 35765.92 examples/s]\nGenerating test split: 100%|██████| 1767/1767 [00:00<00:00, 36476.16 examples/s]\nGenerating validation split: 100%|█| 1267/1267 [00:00<00:00, 35214.02 examples/s\n100%|████████████████████████████████████| 1267/1267 [00:00<00:00, 91019.67it/s]\n100%|██████████████████████████████████████| 5153/5153 [00:08<00:00, 600.87it/s]\nRunning loglikelihood requests: 100%|██████| 7687/7687 [00:15<00:00, 508.10it/s]\nbootstrapping for stddev: perplexity\n100%|█████████████████████████████████████████| 100/100 [00:24<00:00,  4.11it/s]\nfatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\nhf (pretrained=HuggingFaceTB/SmolLM-135M-Instruct,dtype=float16), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 256\n|    Tasks     |Version|Filter|n-shot|  Metric  |   | Value |   |Stderr|\n|--------------|------:|------|-----:|----------|---|------:|---|-----:|\n|lambada_openai|      1|none  |     0|acc       |↑  | 0.3382|±  |0.0066|\n|              |       |none  |     0|perplexity|↓  |44.0071|±  |1.8850|\n|winogrande    |      1|none  |     0|acc       |↑  | 0.5162|±  |0.0140|\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Data Parallel\n! accelerate launch -m lm_eval --model hf --model_args pretrained=HuggingFaceTB/SmolLM-135M-Instruct,dtype=\"float16\" \\\n--tasks hellaswag --batch_size 256 --output_path \"/kaggle/working/out\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T11:57:52.371852Z","iopub.execute_input":"2025-04-26T11:57:52.372652Z","iopub.status.idle":"2025-04-26T12:00:10.787845Z","shell.execute_reply.started":"2025-04-26T11:57:52.372616Z","shell.execute_reply":"2025-04-26T12:00:10.787043Z"}},"outputs":[{"name":"stdout","text":"2025-04-26 11:58:05.222479: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745668685.247531     229 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745668685.254784     229 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-04-26 11:58:05.669077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745668685.694015     230 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745668685.701723     230 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nREADME.md: 100%|███████████████████████████| 6.84k/6.84k [00:00<00:00, 25.9MB/s]\nhellaswag.py: 100%|████████████████████████| 4.36k/4.36k [00:00<00:00, 20.6MB/s]\ndataset_infos.json: 100%|██████████████████| 2.53k/2.53k [00:00<00:00, 13.1MB/s]\nDownloading data: 100%|█████████████████████| 47.5M/47.5M [00:00<00:00, 187MB/s]\nDownloading data: 100%|█████████████████████| 11.8M/11.8M [00:00<00:00, 227MB/s]\nDownloading data: 100%|█████████████████████| 12.2M/12.2M [00:00<00:00, 306MB/s]\nGenerating train split: 100%|███| 39905/39905 [00:02<00:00, 13931.26 examples/s]\nGenerating test split: 100%|████| 10003/10003 [00:00<00:00, 13751.85 examples/s]\nGenerating validation split: 100%|█| 10042/10042 [00:00<00:00, 14651.86 examples\nMap: 100%|███████████████████████| 39905/39905 [00:06<00:00, 6172.72 examples/s]\nMap: 100%|███████████████████████| 39905/39905 [00:06<00:00, 6158.56 examples/s]\nMap: 100%|███████████████████████| 10042/10042 [00:01<00:00, 6333.14 examples/s]\nMap: 100%|███████████████████████| 10042/10042 [00:01<00:00, 6248.23 examples/s]\n100%|█████████████████████████████████████| 5021/5021 [00:02<00:00, 2434.47it/s]\n100%|█████████████████████████████████████| 5021/5021 [00:02<00:00, 2224.59it/s]\nRunning loglikelihood requests: 100%|████| 20084/20084 [01:12<00:00, 276.75it/s]\nfatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\nhf (pretrained=HuggingFaceTB/SmolLM-135M-Instruct,dtype=float16), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 256\n|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n|---------|------:|------|-----:|--------|---|-----:|---|-----:|\n|hellaswag|      1|none  |     0|acc     |↑  |0.3464|±  |0.0047|\n|         |       |none  |     0|acc_norm|↑  |0.4197|±  |0.0049|\n\n[rank0]:[W426 12:00:07.352257638 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"! lm_eval --model hf \\\n--model_args pretrained=NousResearch/Llama-2-13b-chat-hf,dtype=\"float16\" \\\n--tasks hellaswag --device \"cuda:0\" --batch_size 2 --output_path \"/kaggle/working/out\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:00:40.351511Z","iopub.execute_input":"2025-04-26T12:00:40.352293Z","iopub.status.idle":"2025-04-26T12:03:43.622240Z","shell.execute_reply.started":"2025-04-26T12:00:40.352258Z","shell.execute_reply":"2025-04-26T12:03:43.621112Z"}},"outputs":[{"name":"stdout","text":"2025-04-26 12:00:44.728970: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745668844.753342     306 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745668844.760679     306 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nconfig.json: 100%|█████████████████████████████| 608/608 [00:00<00:00, 3.17MB/s]\ntokenizer_config.json: 100%|███████████████████| 746/746 [00:00<00:00, 6.12MB/s]\ntokenizer.model: 100%|███████████████████████| 500k/500k [00:00<00:00, 13.1MB/s]\nadded_tokens.json: 100%|██████████████████████| 21.0/21.0 [00:00<00:00, 104kB/s]\nspecial_tokens_map.json: 100%|█████████████████| 435/435 [00:00<00:00, 2.34MB/s]\nmodel.safetensors.index.json: 100%|████████| 33.4k/33.4k [00:00<00:00, 16.0MB/s]\nmodel-00001-of-00003.safetensors: 100%|████▉| 9.95G/9.95G [00:24<00:00, 409MB/s]\nmodel-00002-of-00003.safetensors: 100%|████▉| 9.90G/9.90G [00:40<00:00, 244MB/s]\nmodel-00003-of-00003.safetensors: 100%|████▉| 6.18G/6.18G [00:24<00:00, 248MB/s]\nLoading checkpoint shards:  33%|██████            | 1/3 [01:15<02:31, 75.86s/it]\nTraceback (most recent call last):\n  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n    sys.exit(cli_evaluate())\n             ^^^^^^^^^^^^^^\n  File \"/kaggle/working/lm-evaluation-harness/lm_eval/__main__.py\", line 449, in cli_evaluate\n    results = evaluator.simple_evaluate(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/lm-evaluation-harness/lm_eval/utils.py\", line 439, in _wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/lm-evaluation-harness/lm_eval/evaluator.py\", line 226, in simple_evaluate\n    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/lm-evaluation-harness/lm_eval/api/model.py\", line 151, in create_from_arg_string\n    return cls(**args, **args2)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 193, in __init__\n    self._create_model(\n  File \"/kaggle/working/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 594, in _create_model\n    self._model = self.AUTO_MODEL_CLASS.from_pretrained(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4399, in from_pretrained\n    ) = cls._load_pretrained_model(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4833, in _load_pretrained_model\n    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 787, in _load_state_dict_into_meta_model\n    param = param[...]\n            ~~~~~^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 7291 has 14.74 GiB memory in use. Of the allocated memory 14.62 GiB is allocated by PyTorch, and 18.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# GPU Parallel\n! lm_eval --model hf \\\n--model_args pretrained=NousResearch/Llama-2-13b-chat-hf,dtype=\"float16\",parallelize=True \\\n--tasks hellaswag --batch_size 16 --output_path \"/kaggle/working/out\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:04:51.107361Z","iopub.execute_input":"2025-04-26T12:04:51.107744Z","iopub.status.idle":"2025-04-26T12:09:03.610075Z","shell.execute_reply.started":"2025-04-26T12:04:51.107711Z","shell.execute_reply":"2025-04-26T12:09:03.609314Z"}},"outputs":[{"name":"stdout","text":"2025-04-26 12:04:56.762878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745669096.785533     987 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745669096.792578     987 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading checkpoint shards: 100%|██████████████████| 3/3 [01:51<00:00, 37.27s/it]\ngeneration_config.json: 100%|██████████████████| 196/196 [00:00<00:00, 1.43MB/s]\n100%|███████████████████████████████████| 10042/10042 [00:03<00:00, 2733.16it/s]\nRunning loglikelihood requests:   1%|     | 450/40168 [01:35<2:20:39,  4.71it/s]^C\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# GPU and Data Parallel\n! accelerate launch -m lm_eval --model hf \\\n--model_args pretrained=NousResearch/Llama-2-13b-chat-hf,dtype=\"float16\",parallelize=True \\\n--tasks hellaswag --batch_size 2 --output_path \"/kaggle/working/out\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:09:51.355152Z","iopub.execute_input":"2025-04-26T12:09:51.355964Z","iopub.status.idle":"2025-04-26T12:13:29.455885Z","shell.execute_reply.started":"2025-04-26T12:09:51.355932Z","shell.execute_reply":"2025-04-26T12:13:29.454649Z"}},"outputs":[{"name":"stdout","text":"2025-04-26 12:10:04.501265: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-26 12:10:04.501346: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745669404.526723    1020 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745669404.526792    1021 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745669404.534634    1020 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745669404.534636    1021 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading checkpoint shards: 100%|██████████████████| 3/3 [02:06<00:00, 42.20s/it]\n100%|█████████████████████████████████████| 5021/5021 [00:01<00:00, 2665.51it/s]\nRunning loglikelihood requests:   1%|     | 265/20084 [00:48<1:01:35,  5.36it/s]^C\nW0426 12:13:28.748000 1011 torch/distributed/elastic/agent/server/api.py:704] Received 2 death signal, shutting down workers\nW0426 12:13:28.749000 1011 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1020 closing signal SIGINT\nW0426 12:13:28.750000 1011 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1021 closing signal SIGINT\n[rank0]: Traceback (most recent call last):\n[rank0]:   File \"<frozen runpy>\", line 198, in _run_module_as_main\n[rank0]:   File \"<frozen runpy>\", line 88, in _run_code\n[rank0]:   File \"/kaggle/working/lm-evaluation-harness/lm_eval/__main__.py\", line 530, in <module>\n[rank0]:     cli_evaluate()\n[rank0]:   File \"/kaggle/working/lm-evaluation-harness/lm_eval/__main__.py\", line 449, in cli_evaluate\n[rank0]:     results = evaluator.simple_evaluate(\n[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/kaggle/working/lm-evaluation-harness/lm_eval/utils.py\", line 439, in _wrapper\n[rank0]:     return fn(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/kaggle/working/lm-evaluation-harness/lm_eval/evaluator.py\", line 338, in simple_evaluate\n[rank0]:     results = evaluate(\n[rank0]:               ^^^^^^^^^\n[rank0]:   File \"/kaggle/working/lm-evaluation-harness/lm_eval/utils.py\", line 439, in _wrapper\n[rank0]:     return fn(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/kaggle/working/lm-evaluation-harness/lm_eval/evaluator.py\", line 570, in evaluate\n[rank0]:     resps = getattr(lm, reqtype)(cloned_reqs)\n[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/kaggle/working/lm-evaluation-harness/lm_eval/api/model.py\", line 382, in loglikelihood\n[rank0]:     return self._loglikelihood_tokens(new_reqs, disable_tqdm=disable_tqdm)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/kaggle/working/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 1211, in _loglikelihood_tokens\n[rank0]:     self._model_call(batched_inps, **call_kwargs),\n[rank0]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/kaggle/working/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 894, in _model_call\n[rank0]:     return self.model(inps).logits\n[rank0]:            ^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n[rank0]:     return self._call_impl(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n[rank0]:     return forward_call(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\", line 965, in wrapper\n[rank0]:     output = func(self, *args, **kwargs)\n[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n[rank0]:     return func(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 821, in forward\n[rank0]:     outputs: BaseModelOutputWithPast = self.model(\n[rank0]:                                        ^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n[rank0]:     return self._call_impl(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n[rank0]:     return forward_call(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\", line 965, in wrapper\n[rank0]:     output = func(self, *args, **kwargs)\n[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 571, in forward\n[rank0]:     layer_outputs = decoder_layer(\n[rank0]:                     ^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n[rank0]:     return self._call_impl(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n[rank0]:     return forward_call(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 334, in forward\n[rank0]:     hidden_states = self.mlp(hidden_states)\n[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n[rank0]:     return self._call_impl(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n[rank0]:     return forward_call(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 172, in forward\n[rank0]:     down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n[rank0]:                                            ^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n[rank0]:     return self._call_impl(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1844, in _call_impl\n[rank0]:     return inner()\n[rank0]:            ^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1790, in inner\n[rank0]:     result = forward_call(*args, **kwargs)\n[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n[rank0]:     return F.linear(input, self.weight, self.bias)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_library/simple_registry.py\", line 82, in find_torch_dispatch_rule\n[rank0]:     def find_torch_dispatch_rule(op, torch_dispatch_class: type) -> Optional[Callable]:\n[rank0]:     \n[rank0]: KeyboardInterrupt\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}